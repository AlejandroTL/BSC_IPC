{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.patches as mpatches\n",
    "import umap\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "source": [
    "### Some functions\n",
    "\n",
    "##### Function to plot UMAP with differente neighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_plot(data,color,components=2):\n",
    "\n",
    "    n_neighbors = [5,15,22,30]\n",
    "\n",
    "    for i in n_neighbors:\n",
    "        reducer = umap.UMAP(n_components=components,n_neighbors=i)\n",
    "        embedding = reducer.fit_transform(data)\n",
    "        embedding_df = pd.DataFrame(embedding)\n",
    "        embedding_df['Subgroups']= color\n",
    "\n",
    "        X_data= embedding_df[0]\n",
    "        Y_data = embedding_df[1]\n",
    "        if components == 3:\n",
    "            Z_data = embedding_df[2]\n",
    "        Sbgrp = embedding_df['Subgroups']\n",
    "\n",
    "        cdict = {'Group4': 'pink', 'SHH': 'blue', 'WNT': 'green', 'Group3': 'yellow', 'Generated': 'black', 'Reference': 'red'}\n",
    "        c = [cdict[val] for val in Sbgrp]\n",
    "\n",
    "        plt.figure(figsize=(16,10))\n",
    "        if components == 3:\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.scatter3D(X_data, Y_data, Z_data, c=c)\n",
    "        if components == 2:\n",
    "            plt.scatter(X_data,Y_data,c=c)\n",
    "        pink_c = mpatches.Patch(color='pink', label='Group4')\n",
    "        blue_c = mpatches.Patch(color='blue', label='SHH')\n",
    "        green_c = mpatches.Patch(color='green', label='WNT')\n",
    "        yellow_c = mpatches.Patch(color='yellow', label='Group3')\n",
    "        black_c = mpatches.Patch(color='black', label='Generated')\n",
    "        red_c = mpatches.Patch(color='red', label='Reference')\n",
    "        plt.legend(handles=[pink_c,blue_c,green_c,yellow_c,black_c,red_c])\n",
    "        plt.title('UMAP with n_neighbors %i'%(i))\n",
    "        plt.show()"
   ]
  },
  {
   "source": [
    "##### Function to get embeddings, recontructions, mean and logvar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model,dataloader):\n",
    "    model.eval()\n",
    "    rec_model = np.zeros(shape=(0,12087))\n",
    "    embedding_model = np.zeros(shape=(0,512))\n",
    "    mean_model = np.zeros(shape=(0,512))\n",
    "    logvar_model = np.zeros(shape=(0,512))\n",
    "    with torch.no_grad(): # in validation we don't want to update weights\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(test_dataset)/dataloader.batch_size)):\n",
    "            data = data.view(data.size(0), -1)\n",
    "            reconstruction,mean,logvar, coded = model(data)\n",
    "            rec_model = np.concatenate((rec_model, reconstruction), axis=0)\n",
    "            mean_model = np.concatenate((mean_model, mean), axis=0)\n",
    "            logvar_model = np.concatenate((logvar_model, logvar), axis=0)\n",
    "            embedding_model = np.concatenate((embedding_model,coded),axis=0)\n",
    "    return rec_model, embedding_model, mean_model, logvar_model"
   ]
  },
  {
   "source": [
    "##### Function to generate data from a subgroup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(N,subgroup,test_dataset):\n",
    "\n",
    "    if subgroup == 'G4':\n",
    "        data_mean = standard_g4\n",
    "        data_logvar = logvar_g4\n",
    "    elif subgroup == 'SHH':\n",
    "        data_mean = standard_shh\n",
    "        data_logvar = logvar_shh\n",
    "    elif subgroup == 'G3':\n",
    "        data_mean = standard_g3\n",
    "        data_logvar = logvar_g3  \n",
    "    else:\n",
    "        print(\"Incorrect subgroup\")\n",
    "        return    \n",
    "    \n",
    "    sample = np.zeros(shape=(512,))\n",
    "\n",
    "    for i in range(0,N):\n",
    "        for mean, logvar in zip(data_mean, data_logvar):\n",
    "            resultado = np.random.normal(mean,np.exp(0.5*logvar))\n",
    "            sample = np.concatenate((sample, resultado), axis=0)\n",
    "\n",
    "    sample = sample.reshape(N+1,512)\n",
    "    z = sample[1:]\n",
    "\n",
    "    z = torch.from_numpy(z)\n",
    "    z = z.float()\n",
    "\n",
    "    with torch.no_grad():                 \n",
    "        samples = model.decoder(z)   #decode the data\n",
    "    generated = torch.cat([test_dataset, samples], dim=0) #concat the test data and the generate data to visualize it\n",
    "    new_colors = np.array(['Generated']*len(samples)) #create the reference to paint black the generate examples\n",
    "    colors_generated = np.concatenate((colors,new_colors),axis=0) #concat the colors of the test data and the generate data\n",
    "\n",
    "    return generated, colors_generated"
   ]
  },
  {
   "source": [
    "##### Function to get interpolation data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_interpolation(N,centroid1_mean, centroid1_logvar,centroid2_mean, centroid2_logvar, colors, test_dataset):\n",
    "\n",
    "    z1 = torch.from_numpy(centroid1_mean).float() #Means\n",
    "    z2 = torch.from_numpy(centroid2_logvar).float()\n",
    "\n",
    "    z3 = torch.from_numpy(centroid1_logvar).float() #Logvar\n",
    "    z4 = torch.from_numpy(centroid2_logvar).float()\n",
    "\n",
    "    with torch.no_grad():                 \n",
    "        A = model.decoder(z1)   #decode the data to plot the references\n",
    "        B = model.decoder(z2)   #here only mean because I want the particular data\n",
    "\n",
    "    sample = np.zeros(shape=(0,512))\n",
    "    for i in range(0,N):\n",
    "        mean = i / (N - 1) * z2 + (1 - i / (N - 1) ) * z1 #interpolation mean\n",
    "        logvar = i / (N - 1) * z4 + (1 - i / (N - 1) ) * z3 #interpolation logvar\n",
    "        resultado = np.random.normal(mean,np.exp(0.5*logvar)) #sample from a normal \n",
    "        sample = np.concatenate((sample, resultado), axis=0)\n",
    "    sample = sample.reshape(N,512)\n",
    "    z = sample[1:]\n",
    "\n",
    "    z = torch.from_numpy(z) #preprocessing to introduce samples in NN\n",
    "    z = z.float()\n",
    "\n",
    "    \n",
    "    #GENERATE INTERPOLATION DATA\n",
    "    with torch.no_grad():                 \n",
    "        samples = model.decoder(z)   #decode the data\n",
    "    generated = torch.cat([test_dataset, samples], dim=0) #concat the test data and the generate data to visualize it\n",
    "    new_colors = np.array(['Generated']*len(samples)) #create the reference to paint black the generate examples\n",
    "    colors_generated = np.concatenate((colors,new_colors),axis=0) #concat the colors of the test data and the generate data\n",
    "\n",
    "    # ADD REFERENCES\n",
    "    generated = torch.cat((generated,A,B),axis=0) # add the centroids to the data to plot them\n",
    "\n",
    "    colors_reference = np.array(['Reference']*2) #add label generated\n",
    "    colors_generated = np.concatenate((colors_generated,colors_reference),axis=0) #generate new colors\n",
    "\n",
    "    return generated, colors_generated"
   ]
  },
  {
   "source": [
    "### Load training data (Cavalli)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Medulloblastoma Files\\Medulloblastoma_Cavalli_VAE_data.csv', sep=',', na_values=\".\")\n",
    "print(\"The shape of the data is: \", data.shape)\n",
    "data = data.rename(columns={'Unnamed: 0': 'Patient'})\n",
    "\n",
    "subgroups = pd.read_csv('Medulloblastoma Files\\GSE85218_subgroups.csv', sep=' ',header=None)\n",
    "print(\"The shape of the subgroups is: \", subgroups.shape)"
   ]
  },
  {
   "source": [
    "### Load test data (Northcott)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('Medulloblastoma Files\\Medulloblastoma_Northcott_VAE_data.csv', sep=',', na_values=\".\")\n",
    "print(\"The shape of the data is: \", data_test.shape)\n",
    "data_test = data_test.rename(columns={'Unnamed: 0': 'Patient'})\n",
    "\n",
    "subgroups_test = pd.read_csv('Medulloblastoma Files\\GSE37382_subgroups.csv', sep=' ',header=None)\n",
    "print(\"The shape of the subgroups is: \", subgroups_test.shape)\n",
    "colors = subgroups_test[1].values #column with the subgroups of tumor to label each observation in plots"
   ]
  },
  {
   "source": [
    "### Normalize and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Patient'],axis=1)\n",
    "data_test = data_test.drop(['Patient'],axis=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data) \n",
    "\n",
    "scaler.fit(data_test)\n",
    "data_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "train_dataset = torch.tensor(data.values).float()\n",
    "\n",
    "data_test = pd.DataFrame(data_test)\n",
    "test_dataset = torch.tensor(data_test.values).float()\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "source": [
    "### Load model\n",
    "#### Two layers decoder - two layers decoder\n",
    "#### 512 dimension latent space"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 512\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        #encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=kwargs[\"input_shape\"], out_features=kwargs[\"mid_dim\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=kwargs[\"mid_dim\"], out_features=features*2)\n",
    "        )\n",
    "            \n",
    "        #decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=features, out_features=kwargs[\"mid_dim\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=kwargs[\"mid_dim\"], out_features=kwargs[\"input_shape\"]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def reparametrize(self, mu, log_var):\n",
    "\n",
    "        # mu: mean of the encoder's latent space distribution\n",
    "        # log_var: variance from the encoder's latient space distribution\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*log_var) \n",
    "            eps = torch.randn_like(std) \n",
    "            sample = mu + (eps*std) \n",
    "        else:\n",
    "            sample = mu\n",
    "        return sample\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        mu_logvar = self.encoder(x).view(-1,2,features)\n",
    "        mu = mu_logvar[:, 0, :] \n",
    "        log_var = mu_logvar[:, 1, :] \n",
    "\n",
    "        z = self.reparametrize(mu,log_var) \n",
    "        reconstruction = self.decoder(z)\n",
    "        \n",
    "        return reconstruction, mu, log_var, z\n",
    "    \n",
    "model = VAE(input_shape=12087, mid_dim=4096)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "source": [
    "### Load trained model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './vaeDecoderPrunned512000001.pth'\n",
    "model = VAE(input_shape=12087, mid_dim=4096)\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "source": [
    "### Get embeddings, mean and logvar from Northcott data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed, coded, mean, logvar = get_embeddings(model, test_loader)"
   ]
  },
  {
   "source": [
    "### Calculate centroids of subgroups"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = pd.DataFrame(mean)\n",
    "mean['Subgroup'] = subgroups_test[1] #add subgroups column to the embedding data\n",
    "\n",
    "mean_shh = mean[mean['Subgroup'] == 'SHH']\n",
    "mean_g3 = mean[mean['Subgroup'] == 'Group3']\n",
    "mean_g4 = mean[mean['Subgroup'] == 'Group4']\n",
    "\n",
    "# Centroids of Means\n",
    "standard_shh = mean_shh.mean().values.reshape(1,512) \n",
    "standard_g3 = mean_g3.mean().values.reshape(1,512)\n",
    "standard_g4 = mean_g4.mean().values.reshape(1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logvar = pd.DataFrame(mean)\n",
    "logvar['Subgroup'] = subgroups_test[1] #add subgroups column to the embedding data\n",
    "\n",
    "logvar_shh = logvar[logvar['Subgroup'] == 'SHH']\n",
    "logvar_g3 = logvar[logvar['Subgroup'] == 'Group3']\n",
    "logvar_g4 = logvar[logvar['Subgroup'] == 'Group4']\n",
    "\n",
    "logvar_shh = logvar_shh.mean().values.reshape(1,512)\n",
    "logvar_g3 = logvar_g3.mean().values.reshape(1,512)\n",
    "logvar_g4 = logvar_g4.mean().values.reshape(1,512)"
   ]
  },
  {
   "source": [
    "### Calculate euclidean distance between centroids"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_g3_shh = np.cumsum(abs(standard_shh - standard_g3))\n",
    "distance_G3G4 = np.cumsum(abs(standard_g4 - standard_g3))\n",
    "distance_shh_G4 = np.cumsum(abs(standard_g4 - standard_shh))\n",
    "\n",
    "print(\"Distance G3-SHH: \",distance_g3_shh[-1])\n",
    "print(\"Distance G3-G4: \",distance_G3G4[-1])\n",
    "print(\"Distance SHH-G4: \",distance_shh_G4[-1])"
   ]
  },
  {
   "source": [
    "### Sample from the distribution of some subgroup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated, new_colors = data_generation(48, 'G3', test_dataset) #generate 48 data of G3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_plot(generated,new_colors) #plot it in UMAP with 2 dimensions\n",
    "#umap_plot(generated,new_colors,3) plot it in UMAP with 3 dimensions"
   ]
  },
  {
   "source": [
    "### Interpolate between centroids of two subgroups"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_data, interpolation_colors = data_interpolation(32,standard_g3, logvar_g3,standard_g4, logvar_g4, colors, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(318,)\ntorch.Size([318, 12087])\n"
     ]
    }
   ],
   "source": [
    "umap_plot(interpolation_data,interpolation_colors) #plot it in UMAP with 2 dimensions"
   ]
  }
 ]
}